{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b27860",
   "metadata": {},
   "source": [
    "# What\n",
    "分类任务，支持两种模式\n",
    "1. Folder模式，需要输入`train`, `valid`两个测试集对应的目录。`labels.txt`，需要训练的label，里面每个类别一行。\n",
    "2. List模式，需要输入`train`, `valid`两个测试集对应的训练文件，每行一个样本。`labels.txt`是可选参数，里面每个类别一行。`data_pattern`一个通用的目录，与train、val中的第一列进行拼接。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd7e75",
   "metadata": {},
   "source": [
    "### 支持的模型名称\n",
    "\n",
    "模型名称替换代码中的 `model_name`变量的值。\n",
    "\n",
    "| **模型系列** | **模型名称**                                                 |\n",
    "| ------------ | ------------------------------------------------------------ |\n",
    "| AlexNet      | alexnet                                                      |\n",
    "| VGG          | vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19_bn, vgg19 |\n",
    "| ResNet       | resnet18, resnet34, resnet50, resnet101, resnet152, resnext50_32x4d, resnext101_32x8d, wide_resnet50_2, wide_resnet101_2 |\n",
    "| DenseNet     | densenet121, densenet169, densenet201, densenet161           |\n",
    "| Inception    | googlenet, inception_v3                                      |\n",
    "| SqueezeNet   | squeezenet1_0, squeezenet1_1                                 |\n",
    "| ShuffleNetV2 | shufflenet_v2_x2_0, shufflenet_v2_x0_5, shufflenet_v2_x1_0, shufflenet_v2_x1_5 |\n",
    "| MobileNet    | mobilenet_v2, mobilenet_v3_large, mobilenet_v3_small         |\n",
    "| MNASNet      | mnasnet0_5, mnasnet0_75, mnasnet1_0, mnasnet1_3              |\n",
    "| ViT       | ViT, SimpleViT, Crossformer, TwinsSVT|\n",
    "\n",
    "![](http://medai.icu/storage/attachments/2023/10/10/RHd9eH5U67VsOP8vqyNyBD5nGYREejkAKx3Jw16X.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e861016",
   "metadata": {},
   "source": [
    "### List模式\n",
    "\n",
    "在Onekey中List模式一般是采用labelme标注出来的结果，如果要使用自己的数据应用List模式，需要根据自己的实际情况对数据进行处理。\n",
    "\n",
    "* `train.txt`，训练数据列表，中间用\\t（Tab水平制表符）进行分割。\n",
    "* `val.txt`，验证数据列表，中间用\\t（Tab水平制表符）进行分割。\n",
    "* `labels.txt`，label的集合，表明训练数据多少标签。\n",
    "* `data_pattern`参数，所有数据存在的目录的公共前缀，如果`train.txt`,`val.txt`文件里面存放的是绝对路径，`data_pattern`设置为None即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7050436a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-27 10:21:30 - <frozen core.transformer_factory>:  45]\tINFO\t使用2通道，-([0.485, 0.456])/ ([0.229, 0.224])\n",
      "[2025-04-27 10:21:30 - <frozen core.transformer_factory>:  45]\tINFO\t使用2通道，-([0.485, 0.456])/ ([0.229, 0.224])\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.datasets.ClassificationDataset>: 662]\tINFO\t\u001b[5m\u001b[33mWE RECOMMEND YOU USE SPECIFY dataset_name LIKE list for ListDataset OR folder for FolderDataset.\u001b[0m\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.datasets.ClassificationDataset>:  83]\tINFO\t\u001b[32mParsing record file E:\\\\111thymus\\\\thymus_habitat\\\\sol8. 深度（迁移）学习-单（多）中心-多通道-万能图像融合-临床\\\\调试\\\\2_73 - 副本\\\\train-RND-2.txt\u001b[0m\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.datasets.ClassificationDataset>:  86]\tINFO\t\tChecking file exists in E:\\\\111thymus\\\\thymus_habitat\\\\sol8. 深度（迁移）学习-单（多）中心-多通道-万能图像融合-临床\\\\调试\\\\2_73 - 副本\\\\train-RND-2.txt\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.datasets.ClassificationDataset>: 673]\tINFO\t\u001b[36mWe infer your kwargs to be <class 'onekey_algo.datasets.ClassificationDataset.ListDataset'>.\u001b[0m\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.datasets.ClassificationDataset>: 662]\tINFO\t\u001b[5m\u001b[33mWE RECOMMEND YOU USE SPECIFY dataset_name LIKE list for ListDataset OR folder for FolderDataset.\u001b[0m\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.datasets.ClassificationDataset>:  83]\tINFO\t\u001b[32mParsing record file E:\\\\111thymus\\\\thymus_habitat\\\\sol8. 深度（迁移）学习-单（多）中心-多通道-万能图像融合-临床\\\\调试\\\\2_73 - 副本\\\\val-RND-2.txt\u001b[0m\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.datasets.ClassificationDataset>:  86]\tINFO\t\tChecking file exists in E:\\\\111thymus\\\\thymus_habitat\\\\sol8. 深度（迁移）学习-单（多）中心-多通道-万能图像融合-临床\\\\调试\\\\2_73 - 副本\\\\val-RND-2.txt\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.datasets.ClassificationDataset>: 673]\tINFO\t\u001b[36mWe infer your kwargs to be <class 'onekey_algo.datasets.ClassificationDataset.ListDataset'>.\u001b[0m\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.utils.about_log>: 149]\tINFO\tTrain:Dataset is ListDataset\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.utils.about_log>: 149]\tINFO\t\tNumber of samples: 429\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.utils.about_log>: 149]\tINFO\t\tRoot location: E:\\\\111thymus\\\\thymus_habitat\\\\sol8. 深度（迁移）学习-单（多）中心-多通道-万能图像融合-临床\\\\调试\\\\2_73 - 副本\\\\merges\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.utils.about_log>: 149]\tINFO\t\tLabels file is stored in E:\\111thymus\\thymus_habitat\\sol8. 深度（迁移）学习-单（多）中心-多通道-万能图像融合-临床\\split_info\\labels.txt\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.utils.about_log>: 149]\tINFO\tValid:Dataset is ListDataset\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.utils.about_log>: 149]\tINFO\t\tNumber of samples: 193\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.utils.about_log>: 149]\tINFO\t\tRoot location: E:\\\\111thymus\\\\thymus_habitat\\\\sol8. 深度（迁移）学习-单（多）中心-多通道-万能图像融合-临床\\\\调试\\\\2_73 - 副本\\\\merges\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.classification.run_classification>: 323]\tINFO\tCreating model alexnet...\n",
      "[2025-04-27 10:21:30 - <frozen onekey_algo.classification.run_classification>: 370]\tINFO\tStart training...\n",
      "[2025-04-27 10:21:33 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.075,1\u001b[0m\tLR: \u001b[36m0.009855\u001b[0m\tLoss: \u001b[31m0.692\u001b[0m\tAcc: \u001b[33m68.7500\u001b[0m\t Speed: \u001b[33m10.47\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:34 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.149,2\u001b[0m\tLR: \u001b[36m0.009427\u001b[0m\tLoss: \u001b[31m0.692\u001b[0m\tAcc: \u001b[33m62.5000\u001b[0m\t Speed: \u001b[33m133.46\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:34 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.224,3\u001b[0m\tLR: \u001b[36m0.008743\u001b[0m\tLoss: \u001b[31m0.690\u001b[0m\tAcc: \u001b[32m71.8750\u001b[0m\t Speed: \u001b[33m134.28\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:34 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.298,4\u001b[0m\tLR: \u001b[36m0.007840\u001b[0m\tLoss: \u001b[31m0.689\u001b[0m\tAcc: \u001b[33m68.7500\u001b[0m\t Speed: \u001b[33m123.60\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:34 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.373,5\u001b[0m\tLR: \u001b[36m0.006773\u001b[0m\tLoss: \u001b[31m0.688\u001b[0m\tAcc: \u001b[33m68.7500\u001b[0m\t Speed: \u001b[33m121.35\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:35 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.448,6\u001b[0m\tLR: \u001b[36m0.005603\u001b[0m\tLoss: \u001b[31m0.686\u001b[0m\tAcc: \u001b[33m68.7500\u001b[0m\t Speed: \u001b[33m126.43\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:35 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.522,7\u001b[0m\tLR: \u001b[36m0.004397\u001b[0m\tLoss: \u001b[31m0.683\u001b[0m\tAcc: \u001b[32m81.2500\u001b[0m\t Speed: \u001b[33m135.84\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:35 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.597,8\u001b[0m\tLR: \u001b[36m0.003227\u001b[0m\tLoss: \u001b[31m0.687\u001b[0m\tAcc: \u001b[33m65.6250\u001b[0m\t Speed: \u001b[33m125.52\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:35 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.671,9\u001b[0m\tLR: \u001b[36m0.002160\u001b[0m\tLoss: \u001b[31m0.686\u001b[0m\tAcc: \u001b[33m68.7500\u001b[0m\t Speed: \u001b[33m125.56\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:36 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.746,10\u001b[0m\tLR: \u001b[36m0.001257\u001b[0m\tLoss: \u001b[31m0.681\u001b[0m\tAcc: \u001b[32m78.1250\u001b[0m\t Speed: \u001b[33m133.45\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:36 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.821,11\u001b[0m\tLR: \u001b[36m0.000573\u001b[0m\tLoss: \u001b[31m0.685\u001b[0m\tAcc: \u001b[33m68.7500\u001b[0m\t Speed: \u001b[33m135.40\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:36 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.895,12\u001b[0m\tLR: \u001b[36m0.000145\u001b[0m\tLoss: \u001b[31m0.685\u001b[0m\tAcc: \u001b[33m68.7500\u001b[0m\t Speed: \u001b[33m130.27\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:36 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m0.970,13\u001b[0m\tLR: \u001b[36m0.000000\u001b[0m\tLoss: \u001b[31m0.682\u001b[0m\tAcc: \u001b[32m75.0000\u001b[0m\t Speed: \u001b[33m126.14\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:37 - <frozen onekey_algo.classification.run_classification>: 196]\tINFO\tPhase: \u001b[32mtrain\u001b[0m\tEpoch: \u001b[35m1.044,14\u001b[0m\tLR: \u001b[36m0.000145\u001b[0m\tLoss: \u001b[31m0.691\u001b[0m\tAcc: \u001b[33m53.8462\u001b[0m\t Speed: \u001b[33m122.42\u001b[0m img/s\tTime: \u001b[32m0hrs:0min\u001b[0m\n",
      "[2025-04-27 10:21:38 - <frozen onekey_algo.classification.run_classification>: 251]\tINFO\tPhase: \u001b[36mvalid\u001b[0m\tacc: \u001b[32m67.358\u001b[0m\tSpeed: \u001b[31m138.4569\u001b[0mimg/s\tTime: \u001b[32m1.39\u001b[0ms\n",
      "[2025-04-27 10:21:38 - <frozen onekey_algo.classification.run_classification>: 387]\tINFO\tDone for training. Best metric is 67.35751295336787@1 epoch. Average for last 5 iters is 67.35751295336787\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from onekey_algo.classification.run_classification import main as clf_main\n",
    "from collections import namedtuple\n",
    "from onekey_algo import get_param_in_cwd\n",
    "\n",
    "# 设置参数\n",
    "compare_settings = get_param_in_cwd('compare_settings')\n",
    "train_f = get_param_in_cwd('train_file') or 'split_info/train-RND-0.txt'\n",
    "val_f = get_param_in_cwd('val_file') or 'split_info/val-RND-0.txt'\n",
    "labels_f = 'split_info/labels.txt'\n",
    "data_pattern =  get_param_in_cwd('data_pattern')\n",
    "\n",
    "for task_type, dp, ic in zip(compare_settings['task_types'], compare_settings['data_patterns'], compare_settings['in_channels']):\n",
    "    for model_name in compare_settings['model_names']:\n",
    "        params = dict(train=train_f,\n",
    "                      valid=val_f,\n",
    "                      labels_file=labels_f,\n",
    "                      data_pattern=dp,\n",
    "                      j=0,\n",
    "                      max2use=None,\n",
    "                      val_max2use=None,\n",
    "                      batch_balance=False,\n",
    "                      normalize_method='imagenet',\n",
    "                      model_name=model_name,\n",
    "                      vit_settings = {'patch_size': 64, 'dim': 1024, 'depth': 6, 'heads': 16, 'mlp_dim': 768},\n",
    "                      gpus=[0],\n",
    "                      batch_size=32,\n",
    "                      epochs=get_param_in_cwd('epoch', 50),\n",
    "                      init_lr=0.01,\n",
    "                      optimizer='sgd',\n",
    "                      retrain=None,\n",
    "                      model_root=os.path.join(get_param_in_cwd('model_root', 'dl_models'), task_type),\n",
    "                      add_date=False,\n",
    "                      iters_start=0,\n",
    "                      iters_verbose=1,\n",
    "                      save_per_epoch=False,\n",
    "                      in_channels=ic,\n",
    "                      pretrained=False)\n",
    "        # 训练模型\n",
    "        Args = namedtuple(\"Args\", params)\n",
    "        clf_main(Args(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d403a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
